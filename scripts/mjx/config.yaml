project_name: stompy_walk
experiment_name: default_walk
num_timesteps: 150000000
num_evals: 15000
reward_scaling: 0.1
episode_length: 1000
normalize_observations: true
action_repeat: 1
unroll_length: 10
num_minibatches: 32
num_updates_per_batch: 8
discounting: 0.97
learning_rate: 0.0003
entropy_cost: 0.001
num_envs: 1
# num_envs: 1
batch_size: 512
seed: 0
env_name: stompy
reward_params:
  rew_forward:
    weight: 1.25
  rew_healthy:
    weight: 5.0
    healthy_z_lower: -1.0
    healthy_z_upper: 1.0
  rew_height:
    weight: 0.8
  rew_ctrl_cost:
    weight: 0.1
policy_hidden_layer_sizes: [64, 64, 64, 64, 64]
value_hidden_layer_sizes: [256, 256, 256, 256, 256]
terminate_when_unhealthy: true
reset_noise_scale: 0.01
exclude_current_positions_from_observation: true
log_reward_breakdown: true